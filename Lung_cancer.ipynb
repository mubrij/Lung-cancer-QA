{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "books_path = \"/home/unicconaiadmin/Music1/Msa/Lung cancer\"\n",
    "booklets = os.listdir(books_path)\n",
    "loaders = [PyPDFLoader(os.path.join(books_path, booklet)) for booklet in booklets]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unicconaiadmin/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "chroma_vectorstore = Chroma.from_documents(docs, embedding)\n",
    "chroma_retriever = chroma_vectorstore.as_retriever()\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever,chroma_retriever], weights=[0.5,0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What type of lung cancer do I have? __________________________________________\\nWhat stage of lung cancer is it? ___________________________________________\\nHas my tumor been sent for genetic or other biomarker testing? If so, what do the \\nresults mean for me? __________________________________________________________\\n______________________________________________________________________________\\n______________________________________________________________________________\\nCan you remove the cancer with surgery, and would that be helpful? ____________\\n_____________________________________________________________________________\\nWhat treatment do you recommend and why?_______________________________\\n______________________________________________________________________________\\n______________________________________________________________________________\\n_____________________________________________________________________________\\nWhat are the risks of this treatment? _________________________________________\\n______________________________________________________________________________  \\nAre there other treatments besides the one you recommend? ______________________\\n______________________________________________________________________________  \\nHow long will the treatment take? ___________________________________________\\nWhat are the side effects of the treatment? What can I do to prepare for them? ____\\n____________________________________________________________________________________________________________________________________________________________\\nHow will treatment affect my everyday life? ______________________________________\\n______________________________________________________________________________QUESTIONS TO ASK YOUR HEALTH CARE TEAM'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever.get_relevant_documents(\"what is tumor\")[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an intelligent AI doctor assistant. Your role is to analyze patient information and provide insightful responses and guidance. Additional context will be provided along with patient queries. If the context is not helpful, provide an appropriate response to the given query. \n",
    "\n",
    "Context: {context}\n",
    "Query: {question}\n",
    "Thoughtful Response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=800,\n",
    "    top_p=0,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rag(qa, query, patient_details):\n",
    "    combined_query = f\"{query} Patient details: {patient_details}\"\n",
    "    result = qa.run(combined_query)\n",
    "    return result\n",
    "\n",
    "def to_markdown(text):\n",
    "    text = text.replace('â€¢', '  *')\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"tell me how good is my Blod pressure.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Based on your blood pressure reading of 120/80, it falls within the normal range for adults. However, it is important to continue monitoring your blood pressure regularly and make healthy lifestyle choices to maintain a healthy blood pressure. If you have any concerns or notice any changes, please consult with your doctor for further guidance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_details = {\n",
    "    \"name\": \"Mubarak\",\n",
    "    \"age\": 18,\n",
    "    \"temperature\": 98.6,\n",
    "    \"blood_pressure\": \"120/80\"\n",
    "}\n",
    "\n",
    "result = test_rag(qa, input_query, patient_details)\n",
    "to_markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
